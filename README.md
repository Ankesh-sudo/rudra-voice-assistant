# Rudra â€” Intelligent Voice Assistant ğŸ§ ğŸ™ï¸

Rudra is a modular, Python-based intelligent voice assistant designed to run reliably on Linux systems.  
The project is built step-by-step with a strong emphasis on **architecture, stability, and extensibility**, rather than quick or fragile features.

The long-term vision is to evolve Rudra into an **offline-first, algorithm-driven AI assistant**, capable of system control, memory, and natural interaction across devices.

---

## ğŸ”– Project Status

### âœ… Current Stable Milestone: **Day 15 â€” Follow-up Intelligence & Context Isolation**

Day 15 finalizes Rudraâ€™s **conversation follow-up system**, making references like *â€œopen it againâ€* safe, deterministic, and production-ready.

All **Day 15 hard tests pass**, and the system is now locked as stable.

### What Day 15 delivers:

- [x] Reference-based follow-ups (`it`, `again`, `them`)
- [x] Intent-isolated context replay (system vs filesystem)
- [x] Action-mismatch safe fallback (no false blocking)
- [x] Context timeout handling (expired context blocked)
- [x] Dangerous intent replay blocked (terminal safety)
- [x] UNKNOWN intent does not pollute context
- [x] Entity leak prevention across intents
- [x] Replay rate limiting & TTL enforcement
- [x] Full hard test suite passing

ğŸ”’ **Day 15 is complete, tested, and locked as a stable milestone.**

---

## ğŸš€ Features (Implemented)

### âœ… Core Assistant

- Enum-driven intent-based command processing
- Modular NLP pipeline (no hardcoded logic)
- Short-term & long-term conversational memory
- MySQL-backed persistent storage
- Clean separation of concerns
- Predictable, debuggable execution flow


### âœ… Input System (Day 8)

- Voice input using Google Speech Recognition
- Text input fallback
- Push-to-talk (press ENTER to speak)
- Configurable input mode (voice / text)
- Controlled listening (no always-on microphone)


### âœ… Input Intelligence (Day 9)

- Input normalization & validation gate
- Minimum-length and word-count filtering
- Repeat suppression (only for previously accepted inputs)
- Confidence refinement after intent scoring
- Safe handling of unknown intents
- Clear retry prompts (no infinite loops)


### âœ… Active Listening & Silence Handling (Day 9)

- Listening state machine (IDLE â†’ ACTIVE â†’ WAITING)
- Automatic silence detection
- Context-aware prompts:
  - â€œIâ€™m listening.â€
  - â€œGoing to sleep.â€
- No accidental intent execution during silence
- Natural conversational pacing


### âœ… System Actions (Day 10)

- Enum-driven Intent â†’ Action abstraction
- Centralized system execution layer
- Linux-safe application launching
- Terminal launch hardened (Snap / GLIBC safe)
- No direct OS access from NLP or skills
- Strict OS boundary enforcement


### âœ… Argument Extraction & Action Gating (Day 12)

Context-aware argument extraction for:
- URLs
- File paths
- Directories
- Search queries

Execution guarantees:
- Validation before execution
- Confidence-based execution gate:
  - High confidence â†’ execute
  - Ambiguous â†’ reject safely
  - Low confidence â†’ request rephrase
- Deterministic behavior (no guessing)


### âœ… Follow-up Intelligence & Context Safety (Day 15)

- Reference resolution (`open it`, `list them again`)
- Intent-class isolation (system â†” filesystem)
- Safe fallback on action mismatch
- Context expiration (TTL-based)
- Dangerous replay prevention
- UNKNOWN intent context reset
- Entity whitelist enforcement per intent
- Test-driven guarantees (hard edge-case suite)


### âœ… Stability, Persistence & Logging

- Structured logging using Loguru
- Detailed debug traces for:
  - Input validation
  - Intent scoring
  - Confidence decisions
  - Argument extraction
  - Action execution
- Graceful handling of speech, microphone, and OS errors
- Secure `.env` usage (never committed)
- Explicit `.env` loading for production reliability

---

## ğŸ§  Project Architecture

```text
core/
â”œâ”€â”€ main.py                  # Entry point
â”œâ”€â”€ assistant.py             # Main assistant loop (state-driven)
â”œâ”€â”€ input_controller.py      # Centralized input handling
â”‚
â”œâ”€â”€ input/
â”‚   â””â”€â”€ input_validator.py   # Input intelligence & repeat control
â”‚
â”œâ”€â”€ speech/
â”‚   â””â”€â”€ google_engine.py     # Google Speech Recognition engine
â”‚
â”œâ”€â”€ nlp/
â”‚   â”œâ”€â”€ normalizer.py        # Text normalization
â”‚   â”œâ”€â”€ tokenizer.py         # Tokenization
â”‚   â”œâ”€â”€ intent.py            # Intent enum definitions
â”‚   â””â”€â”€ argument_extractor.py# Argument extraction
â”‚
â”œâ”€â”€ intelligence/
â”‚   â”œâ”€â”€ intent_scorer.py     # Rule-based intent scoring
â”‚   â””â”€â”€ confidence_refiner.py
â”‚
â”œâ”€â”€ actions/
â”‚   â””â”€â”€ action_executor.py   # Confidence-gated execution layer
â”‚
â”œâ”€â”€ skills/
â”‚   â”œâ”€â”€ basic.py             # Non-system skills
â”‚   â””â”€â”€ system_actions.py    # System action handlers
â”‚
â”œâ”€â”€ context/
â”‚   â”œâ”€â”€ short_term.py        # Session memory
â”‚   â”œâ”€â”€ long_term.py         # Persistent memory (MySQL)
â”‚   â””â”€â”€ follow_up.py         # Day 15 follow-up resolution
â”‚
â”œâ”€â”€ storage/
â”‚   â”œâ”€â”€ mysql.py             # Database connection
â”‚   â””â”€â”€ models.py            # DB models
â”‚
â””â”€â”€ tests/
    â””â”€â”€ test_day15_all_edge_cases.py

---
## ğŸ› ï¸ Tech Stack

- **Language:** Python 3.10+
- **Speech Engine:** Google Speech Recognition
- **Database:** MySQL
- **ORM:** SQLAlchemy
- **Logging:** Loguru
- **OS Target:** Linux (Ubuntu tested)


---
## â–¶ï¸ Running the Assistant

### Activate virtual environment
```bash
source venv/bin/activate
```

### Run Rudra
```bash
python3 -m core.main
```

### Usage

- Press ENTER â†’ speak
- Say commands naturally (e.g., open browser github)
- Silence is handled automatically
- Say exit rudra to quit

---
## ğŸ§­ Roadmap (High Level)

- Day 16â€“25: Advanced skills & multi-step workflows
- Day 26â€“40: Memory intelligence & personalization
- Day 41â€“60: Offline intent engine & algorithms
- Day 61â€“70: Multi-device sync & Raspberry Pi build

---
## ğŸ“Œ Philosophy

Rudra is not built to demo quickly â€”
it is built to last, scale, and evolve.

Every feature must be:
- Predictable
- Debuggable
- Extendable
- Safe to modify later
- No shortcuts. No magic. No fragile abstractions.

---
## ğŸ“œ License

This project is currently for learning, research, and portfolio purposes

License will be finalized once the core system stabilizes

Author: Ankesh
Project: Rudra â€” Intelligent Voice Assistant